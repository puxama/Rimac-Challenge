{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#reading datasets\n",
    "dataset = pd.read_csv('dataset_full.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Tratando missings\n",
    "dataset['NSE_RIMAC'].fillna('Z',inplace=True)\n",
    "dataset['SEGMENTO_INTERNO'].fillna('MADERA', inplace=True)\n",
    "dataset['CANALDES'].fillna('CORREDOR',inplace=True)\n",
    "dataset['CLASEVEHDES'].fillna('OTRO',inplace=True)\n",
    "dataset['USOVEHDES'].fillna('OTRO',inplace=True)\n",
    "\n",
    "marca_auto = ['TOYOTA', 'HYUNDAI','KIA', 'NISSAN', 'SUZUKI', 'VOLKSWAGEN', 'CHEVROLET','HONDA', 'MAZDA',\n",
    "              'SUBARU', 'RENAULT', 'BMW', 'MITSUBISHI', 'JEEP', 'PEUGEOT', 'FORD', 'AUDI', 'MERCEDES BENZ', \n",
    "              'VOLVO', 'GREAT WALL', 'JAC', 'DAIHATSU', 'SSANGYONG', 'CHERY', 'CITROEN', 'SEAT', 'DODGE', \n",
    "              'SSANG YONG', 'FOTON', 'ISUZU', 'HINO', 'FIAT', 'BYD', 'MG', 'CHANGAN', 'INTERNATIONAL', \n",
    "              'BRILLIANCE', 'CHANGHE', 'MINI', 'LAND ROVER', 'PORSCHE', 'GEELY', 'DONG FENG', 'MAHINDRA',\n",
    "              'LIFAN', 'JINBEI', 'DAEWOO', 'BRIDA', 'FREIGHTLINER', 'BAW', 'HAFEI', 'BAIC YINXIANG',\n",
    "              'MITSUBISHI FUSO', 'FAW', 'DFSK', 'BAJAJ', 'KENWORTH', 'BAIC', 'LEXUS', 'ZOTYE', 'YUEJIN',\n",
    "              'TVS', 'SCANIA', 'FORLAND', 'HAIMA', 'JMC', 'GONOW']\n",
    "\n",
    "dataset['MARCAVEHDES'].fillna('OTRO', inplace=True)\n",
    "dataset.loc[~dataset['MARCAVEHDES'].isin(marca_auto),'MARCAVEHDES'] = 'OTRO'\n",
    "\n",
    "var_numeric = ['NUM_PRODUCTOS', 'OK', 'CPP', 'DEFICIENTE', 'DUDOSO', 'PERDIDA',\n",
    "               'SALDO_SBS', 'SALDO_TC_SBS', 'SALDO_VEH_SBS', 'SALDO_HIP_SBS',\n",
    "               'SALDO_PP_SBS', 'SALDO_MICRO_SBS', 'SALDO_PEQUENA_SBS','SALDO_OTROS', 'SUMASEG', \n",
    "               'NRO_SINIESTROS', 'MTO_SINIESTROS', 'DEUDA_HIINI']\n",
    "\n",
    "for var in var_numeric:\n",
    "    dataset[var].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Filtering dataset Periodo > 201606\n",
    "dataset = dataset.loc[dataset['PERIODO']>201606]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#feature engineering\n",
    "dataset['anho'] = dataset['PERIODO']/100\n",
    "dataset['antiguedad_auto'] = dataset['anho'] - dataset['ANOFABRIC']\n",
    "dataset['antiguedad_auto'].fillna(0, inplace=True)\n",
    "\n",
    "dataset['FEC_NACIMIENTO'] = pd.to_datetime(dataset['FEC_NACIMIENTO'], format=\"%d/%m/%Y\")\n",
    "dataset['FEC_ACTUAL'] = pd.to_datetime((dataset['PERIODO']*100)+28, format=\"%Y%m%d\")\n",
    "dataset['FECHA_FIN'] = pd.to_datetime(dataset['FECHA_FIN'])\n",
    "dataset['FECHA_INICIO'] = pd.to_datetime(dataset['FECHA_INICIO'])\n",
    "\n",
    "dataset['edad'] = dataset['anho'] - dataset['FEC_NACIMIENTO'].dt.year\n",
    "dataset['duracion'] = (dataset['FECHA_FIN'] - dataset['FECHA_FIN']).astype('timedelta64[D]')\n",
    "dataset['antiguedad'] = (dataset['FEC_ACTUAL'] - dataset['FECHA_INICIO']).astype('timedelta64[D]')\n",
    "\n",
    "dataset[\"Suma_Deuda_3_meses\"] = dataset.groupby([\"CUC\"])[\"Deuda\"].shift(1).fillna(0) + \\\n",
    "dataset.groupby([\"CUC\"])[\"Deuda\"].shift(2).fillna(0) + \\\n",
    "dataset.groupby([\"CUC\"])[\"Deuda\"].shift(3).fillna(0)\n",
    "\n",
    "dataset[\"Deuda_3_meses\"] = 0\n",
    "dataset.loc[dataset[\"Suma_Deuda_3_meses\"] > 0,\"Deuda_3_meses\"] = 1\n",
    "\n",
    "dataset[\"Suma_Deuda_6_meses\"] = dataset.groupby([\"CUC\"])[\"Deuda\"].shift(1).fillna(0) + \\\n",
    "dataset.groupby([\"CUC\"])[\"Deuda\"].shift(2).fillna(0) + \\\n",
    "dataset.groupby([\"CUC\"])[\"Deuda\"].shift(3).fillna(0)+ \\\n",
    "dataset.groupby([\"CUC\"])[\"Deuda\"].shift(4).fillna(0) + \\\n",
    "dataset.groupby([\"CUC\"])[\"Deuda\"].shift(5).fillna(0) + \\\n",
    "dataset.groupby([\"CUC\"])[\"Deuda\"].shift(6).fillna(0)\n",
    "\n",
    "dataset[\"Deuda_6_meses\"] = 0\n",
    "dataset.loc[dataset[\"Suma_Deuda_6_meses\"] > 0,\"Deuda_6_meses\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nse_dict = {'A':10,'A1': 9, 'A2':8, 'B1':7, 'B2':6, 'C1':5, 'C2':4, 'D1':3, 'D2':2, 'E':1}\n",
    "dataset[\"new_nse\"] = dataset[\"NSE_RIMAC\"].map(nse_dict)\n",
    "dataset.sort_values([\"PERIODO\"], inplace=True)\n",
    "dataset[\"change_nse\"] = dataset[\"new_nse\"] - dataset.groupby([\"CUC\"])[\"new_nse\"].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#discrete to numerical\n",
    "var_discretas = ['NSE_RIMAC', 'CANALDES', 'CLASEVEHDES', 'MARCAVEHDES', 'USOVEHDES', 'SEGMENTO_INTERNO',\n",
    "                'SEXO', 'UBICACION', 'DEPARTAMENTO']\n",
    "for var in var_discretas:\n",
    "    tmp = dataset.groupby([var], as_index=False)['Target'].mean()\n",
    "    tmp = tmp.sort_values('Target', ascending=False).reset_index()\n",
    "    dic_var = {}\n",
    "    for i in tmp.index.values:\n",
    "        dic_var[tmp.ix[i,var]] = i\n",
    "    dataset[var] = dataset[var].map(lambda x:dic_var[x])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#more feature engineering\n",
    "prod_vehi = dataset.groupby([\"PERIODO\",\"CUC\"], as_index=False).agg({'P_AUTO':'nunique'})\n",
    "dataset = dataset.merge(prod_vehi, how='left', on=['PERIODO', 'CUC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48915, 81)\n"
     ]
    }
   ],
   "source": [
    "#test set\n",
    "test_tmp = dataset.loc[(dataset['PERIODO'] == 201612) & (dataset['Deuda'] ==0), ]\n",
    "test_fin = test_tmp.merge(test, how='inner', on='ID_UNICO')\n",
    "print test_tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train set\n",
    "train = dataset.loc[(dataset['Deuda']==0) & (dataset['PERIODO'] != 201612),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#predictores\n",
    "no_var = ['PERIODO', 'ANOFABRIC', 'FECHA_FIN', 'FECHA_INICIO','CUC', 'P_AUTO_x', 'ID_UNICO', 'ID_POLIZA',\n",
    "          'FEC_NACIMIENTO', 'UBIGEO', 'NUM_FACTURAS', 'MONTO_DOLARES', 'Deuda', \n",
    "          'new_Deuda', 'Target', 'PROBA', 'new_nse', 'anho', 'FEC_ACTUAL']\n",
    "\n",
    "predictors = [var for var in dataset if var not in no_var ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6514, 82)\n"
     ]
    }
   ],
   "source": [
    "#train new customers\n",
    "train_new = train.loc[train['antiguedad']<90,]\n",
    "test_fin_new = test_fin.loc[test_fin['antiguedad']<90,]\n",
    "print test_fin_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test old customers\n",
    "train_old = train.loc[train['antiguedad']>=90,]\n",
    "test_fin_old = test_fin.loc[test_fin['antiguedad']>=90,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#MODELO\n",
    "import xgboost as xgb\n",
    "\n",
    "params = {'objective': 'binary:logistic', 'silent': 1,\n",
    "'max_depth': 15, 'eta': 0.4,\n",
    "'subsample': 0.8, 'colsample_bytree': 0.8, 'min_child_weight': 1,\n",
    "'max_delta_step': 0, 'gamma': 0, 'eval_metric': 'auc'}\n",
    "\n",
    "def modeler(train, test, predictors, params, output):\n",
    "    dtrain = xgb.DMatrix(train[predictors], label=train['Target'])\n",
    "    dtest = xgb.DMatrix(test[predictors])\n",
    "    watchlist = [(dtrain, 'dtrain')]\n",
    "    num_rounds = 100\n",
    "    preds = np.zeros(test.shape[0])\n",
    "    for s in np.random.randint(0, 1000000, size=10):\n",
    "        print s\n",
    "        params['seed'] = s\n",
    "        clf_xgb_main = xgb.train(dtrain=dtrain, params=params, num_boost_round=num_rounds, evals=watchlist, \n",
    "                                 verbose_eval=False, )\n",
    "        preds += clf_xgb_main.predict(dtest)\n",
    "    preds = preds/10\n",
    "    test['PROBA'] = preds\n",
    "    test[['ID_UNICO', 'PROBA']].to_csv(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293365\n",
      "35592\n",
      "518478\n",
      "646406\n",
      "548246\n",
      "467962\n",
      "282561\n",
      "845775\n",
      "776948\n",
      "614597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/puxama/.virtualenvs/env_models/lib/python2.7/site-packages/ipykernel/__main__.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "946064\n",
      "974806\n",
      "666656\n",
      "13595\n",
      "332444\n",
      "64694\n",
      "343937\n",
      "364189\n",
      "580473\n",
      "753492\n"
     ]
    }
   ],
   "source": [
    "modeler(train_new, test_fin_new, predictors, params, 'zgz_new.csv')\n",
    "modeler(train_old, test_fin_old, predictors, params, 'zgz_old.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
